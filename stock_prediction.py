# -*- coding: utf-8 -*-
"""Stock-Prediction

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FCs8Kobs22Dk19EKEIfcgiTTJFxADbY6

1. Import Library
2. Upload file dataset
3. Ubah dataset menjadi dataframe pandas
4. Menampilkan 5 baris pertama data frame
5. Cek info dataset
6. Memeriksa apakah ada nilai-nilai yang hilang dalam DataFrame
7. Memeriksa apakah ada data duplikat di dataframe
8. Periksa korelasi tiap data
9. Hapus data yang tidak berkorelasi
10. Cek outlier tiap data
11. Ubah semua data menjadi numerik
12. Normalisasi data dari skala 0 - 1
13. Lihat distribusi data
14. Bagi data train, data test, dana data validation

10. train & test data. cross validation
11. latih model machine learning dengan data validation dan data train
"""

#IMPORT LIBRARY

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Memuat file BBCA.JK.csv menjadi pandas dataframe
df = pd.read_csv('BBCA.JK.csv')

# Menampilkan 5 baris pertama dari dataframe
df.head()

from sklearn.preprocessing import LabelEncoder

df_int = df.copy()
encoder = LabelEncoder()
categorical_data = ['Date']
for kolom in categorical_data:
    df_int[kolom] = encoder.fit_transform(df[kolom])
df_int.head()

# Periksa jumlah kolom, baris, range data, tipe data
df.info()

# Memeriksa apakah ada nilai-nilai yang hilang dalam DataFrame per data
df.isnull()

# Memeriksa apakah ada nilai-nilai yang hilang dalam DataFrame per Kolom
missing_values = df.isnull().any()

# Menampilkan hasil pemeriksaan
print(missing_values)

#Total Data yang hilang pada Data Frame
df.isnull().sum().sum()

# Memeriksa apakah ada data duplikat di dataframe
df.duplicated()

#Total Data yang duplikat pada Data Frame
df.duplicated().sum().sum()

df.corr()

plt.figure(figsize=(10,8))
plt.title('Matriks Korelasi Data')
sns.heatmap(df.corr(), annot=True, linewidths=3)
plt.show()

# Hapus data tidak terpakai
df.drop(['Volume'], axis=1, inplace=True)
df.head()

plt.figure(figsize=(10,8))
plt.title('Matriks Korelasi Data')
sns.heatmap(df.corr(), annot=True, linewidths=3)
plt.show()

#Cek outlier tiap kolom data
plt.boxplot(df["Open"])

plt.boxplot(df["High"])

plt.boxplot(df["Low"])

plt.boxplot(df["Close"])

plt.boxplot(df["Adj Close"])

df["Date"]=pd.to_datetime(df.Date,format="%Y-%m-%d")
df.index=df['Date']

plt.figure(figsize=(16,8))
plt.plot(df["Close"],label='Close Price history')

data=df.sort_index(ascending=True,axis=0)
new_dataset=pd.DataFrame(index=range(0,len(df)),columns=['Date','Close'])

for i in range(0,len(data)):
    new_dataset["Date"][i]=data['Date'][i]
    new_dataset["Close"][i]=data["Close"][i]

new_dataset.head()

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
# %matplotlib inline
from matplotlib.pylab import rcParams
rcParams['figure.figsize']=20,10
from keras.models import Sequential
from keras.layers import LSTM,Dropout,Dense
from sklearn.preprocessing import MinMaxScaler

# Import LabelEncoder dari module sklearn
from sklearn.preprocessing import LabelEncoder


encoder = LabelEncoder()
categorical_data = ['Date']
for kolom in categorical_data:
    new_dataset[kolom] = encoder.fit_transform(df[kolom])

new_dataset.head()

# Import LabelEncoder dari module sklearn
from sklearn.preprocessing import LabelEncoder

# Kode ubah data 'Date' menjadi numerik
df_int = df.copy()
encoder = LabelEncoder()
categorical_data = ['Date']
for kolom in categorical_data:
    df_int[kolom] = encoder.fit_transform(df[kolom])

df_int.head()

df_int["Date"] = (df_int["Date"] - df_int["Date"].min()) / (df_int["Date"].max() - df_int["Date"].min())
df_int["Open"] = (df_int["Open"] - df_int["Open"].min()) / (df_int["Open"].max() - df_int["Open"].min())
df_int["High"] = (df_int["High"] - df_int["High"].min()) / (df_int["High"].max() - df_int["High"].min())
df_int["Low"] = (df_int["Low"] - df_int["Low"].min()) / (df_int["Low"].max() - df_int["Low"].min())
df_int["Close"] = (df_int["Close"] - df_int["Close"].min()) / (df_int["Close"].max() - df_int["Close"].min())
df_int["Adj Close"] = (df_int["Adj Close"] - df_int["Adj Close"].min()) / (df_int["Adj Close"].max() - df_int["Adj Close"].min())
df_int.head()

df_int.min()

df_int.min()
df_int.max()

def distribusi():
    fig,axes = plt.subplots(nrows=2,ncols=3,figsize=(12,8))
    plt.suptitle('Distribusi',fontsize=24)

    def kolom_generator():
        for kolom in df_int:
            yield kolom
    kolom = kolom_generator()

    for i in range(0,2):
        for j in range(0,3):
            k = next(kolom)
            df_int[k].plot(kind='hist',ax=axes[i,j])
            axes[i,j].set_title(k)
    plt.show()
distribusi()

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
model = Sequential()
model.add(LSTM(units=50, return_sequences=True, input_shape=(sequence_length, 5)))  # 5 features
model.add(LSTM(units=50))
model.add(Dense(1))

model.compile(loss='mean_squared_error', optimizer='adam')
model.fit(x_train, y_train, epochs=10, batch_size=64, verbose=2)